{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65874b0e",
   "metadata": {},
   "source": [
    "# SPINN - Structured Pruning Workflow\n",
    "\n",
    "This notebook implements TRUE structured pruning for achieving 2-3x GPU speedup.\n",
    "\n",
    "**Key difference from before:**\n",
    "- ‚ùå Old: Unstructured pruning (zeros in weights) ‚Üí 0.09x speedup (FAILED)\n",
    "- ‚úÖ New: Structured pruning (remove neurons) ‚Üí 2-3x speedup (EXPECTED)\n",
    "\n",
    "**Timeline:** \n",
    "- Cells 1-3: Setup & data loading (5 min)\n",
    "- Cell 4: Train dense baseline (30-40 min) - OR load existing\n",
    "- Cell 5: Structured pruning (60-90 min)\n",
    "- Cell 6-7: Convert & benchmark (5 min)\n",
    "\n",
    "**IMPORTANT:** Run `git pull` in Jupyter terminal first to get new files!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baba4a07",
   "metadata": {},
   "source": [
    "## Cell 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e046e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to SPINN directory and pull latest code\n",
    "import os\n",
    "os.chdir('/home/jupyter-ksenthilkumar/SPINN')\n",
    "\n",
    "# Pull latest changes (includes structured_pruning.py)\n",
    "!git pull origin main\n",
    "\n",
    "# Verify new file exists\n",
    "!ls -la models/structured_pruning.py\n",
    "\n",
    "print(\"\\n‚úÖ Ready to proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789c5bf2",
   "metadata": {},
   "source": [
    "## Cell 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a20a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jupyter-ksenthilkumar/SPINN')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from models.dense_pinn import DensePINN\n",
    "from models.structured_pruning import structured_prune_and_finetune\n",
    "from models.sparse_pinn import convert_dense_to_sparse\n",
    "\n",
    "# Device setup\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "if device == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750f97a",
   "metadata": {},
   "source": [
    "## Cell 3: Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065886f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NASA milling dataset\n",
    "data_path = '/home/jupyter-ksenthilkumar/SPINN/data/mill.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Select features and targets\n",
    "feature_cols = ['X1_ActualPosition', 'X1_ActualVelocity', 'X1_ActualAcceleration',\n",
    "                'X1_CommandPosition', 'X1_CommandVelocity', 'X1_CommandAcceleration',\n",
    "                'X1_CurrentFeedback', 'X1_DCBusVoltage', 'X1_OutputCurrent',\n",
    "                'Y1_ActualPosition', 'Y1_ActualVelocity', 'Y1_ActualAcceleration',\n",
    "                'Y1_CommandPosition', 'Y1_CommandVelocity', 'Y1_CommandAcceleration',\n",
    "                'Y1_CurrentFeedback', 'Y1_DCBusVoltage', 'Y1_OutputCurrent']\n",
    "\n",
    "target_cols = ['Z1_ActualPosition', 'Z1_CurrentFeedback']\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df[target_cols].values\n",
    "\n",
    "# Train/val/test split\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.133, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.164, random_state=42)\n",
    "\n",
    "# Normalize\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_val = scaler_X.transform(X_val)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "y_val = scaler_y.transform(y_val)\n",
    "y_test = scaler_y.transform(y_test)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "X_val_tensor = torch.FloatTensor(X_val).to(device)\n",
    "y_val_tensor = torch.FloatTensor(y_val).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "y_test_tensor = torch.FloatTensor(y_test).to(device)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded successfully\")\n",
    "print(f\"Train: {X_train.shape[0]} samples\")\n",
    "print(f\"Val: {X_val.shape[0]} samples\")\n",
    "print(f\"Test: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391465ee",
   "metadata": {},
   "source": [
    "## Cell 4: Load Dense Baseline Model\n",
    "\n",
    "**Option A:** Load existing trained model (RECOMMENDED - saves 30-40 min)  \n",
    "**Option B:** Train from scratch (if you don't have saved model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15cc867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Load existing model (RECOMMENDED)\n",
    "dense_model_path = '/home/jupyter-ksenthilkumar/SPINN/models/saved/dense_pinn.pth'\n",
    "\n",
    "try:\n",
    "    dense_model = torch.load(dense_model_path)\n",
    "    dense_model = dense_model.to(device)\n",
    "    print(\"‚úÖ Loaded existing dense model\")\n",
    "    \n",
    "    # Verify\n",
    "    dense_model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pred = dense_model(X_val_tensor)\n",
    "        val_r2 = r2_score(y_val_tensor.cpu().numpy(), val_pred.cpu().numpy())\n",
    "    print(f\"Dense model R¬≤: {val_r2:.4f}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Model not found. Use Option B below to train from scratch.\")\n",
    "\n",
    "# Option B: Train from scratch (UNCOMMENT IF NEEDED)\n",
    "# dense_model = DensePINN(input_dim=18, hidden_dims=[512, 512, 512, 256], output_dim=2).to(device)\n",
    "# optimizer = optim.Adam(dense_model.parameters(), lr=0.001)\n",
    "# loss_fn = nn.MSELoss()\n",
    "# \n",
    "# print(\"Training dense baseline (30-40 min)...\")\n",
    "# for epoch in range(100):\n",
    "#     dense_model.train()\n",
    "#     for batch_X, batch_y in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         pred = dense_model(batch_X)\n",
    "#         loss = loss_fn(pred, batch_y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     \n",
    "#     if (epoch + 1) % 10 == 0:\n",
    "#         dense_model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             val_pred = dense_model(X_val_tensor)\n",
    "#             val_loss = loss_fn(val_pred, y_val_tensor)\n",
    "#             val_r2 = r2_score(y_val_tensor.cpu().numpy(), val_pred.cpu().numpy())\n",
    "#         print(f\"Epoch {epoch+1}: Val Loss={val_loss:.6f}, R¬≤={val_r2:.4f}\")\n",
    "# \n",
    "# torch.save(dense_model, dense_model_path)\n",
    "# print(f\"‚úÖ Saved to {dense_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ae6478",
   "metadata": {},
   "source": [
    "## Cell 5: Structured Pruning Training\n",
    "\n",
    "**‚è±Ô∏è Time: 60-90 minutes**\n",
    "\n",
    "This will:\n",
    "1. Calculate neuron importance (L1 norm)\n",
    "2. Remove least important neurons (physically shrink layers)\n",
    "3. Fine-tune for 10 epochs\n",
    "4. Repeat 3 times to reach 68.5% sparsity\n",
    "\n",
    "Expected result: `[18 ‚Üí 512 ‚Üí 512 ‚Üí 512 ‚Üí 256 ‚Üí 2]` becomes `[18 ‚Üí ~256 ‚Üí ~256 ‚Üí ~256 ‚Üí ~128 ‚Üí 2]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03897ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRUCTURED PRUNING - TRUE GPU SPEEDUP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration\n",
    "TARGET_SPARSITY = 0.685  # 68.5% parameter reduction\n",
    "N_PRUNE_ROUNDS = 3       # Gradual pruning\n",
    "FINETUNE_EPOCHS = 10     # Fine-tune after each prune\n",
    "\n",
    "# Dense baseline stats\n",
    "dense_params = sum(p.numel() for p in dense_model.parameters())\n",
    "print(f\"\\nüìä Dense Baseline:\")\n",
    "print(f\"   Parameters: {dense_params:,}\")\n",
    "\n",
    "# Define loss and optimizer factory\n",
    "def pinn_loss(predictions, targets):\n",
    "    return nn.MSELoss()(predictions, targets)\n",
    "\n",
    "def optimizer_factory(model):\n",
    "    return optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"\\nüî™ Pruning Configuration:\")\n",
    "print(f\"   Target sparsity: {TARGET_SPARSITY*100:.1f}%\")\n",
    "print(f\"   Prune rounds: {N_PRUNE_ROUNDS}\")\n",
    "print(f\"   Fine-tune epochs: {FINETUNE_EPOCHS}\")\n",
    "print(f\"\\n‚è±Ô∏è Estimated time: 60-90 minutes\")\n",
    "print(f\"\\n{'='*60}\\n\")\n",
    "\n",
    "# Run structured pruning\n",
    "spinn_model = structured_prune_and_finetune(\n",
    "    model=dense_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer_fn=optimizer_factory,\n",
    "    loss_fn=pinn_loss,\n",
    "    device=device,\n",
    "    target_sparsity=TARGET_SPARSITY,\n",
    "    n_prune_rounds=N_PRUNE_ROUNDS,\n",
    "    finetune_epochs=FINETUNE_EPOCHS\n",
    ")\n",
    "\n",
    "# Final statistics\n",
    "pruned_params = sum(p.numel() for p in spinn_model.parameters())\n",
    "actual_sparsity = (1 - pruned_params / dense_params) * 100\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úÖ STRUCTURED PRUNING COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nüìä Results:\")\n",
    "print(f\"   Dense parameters:  {dense_params:,}\")\n",
    "print(f\"   SPINN parameters:  {pruned_params:,}\")\n",
    "print(f\"   Reduction:         {actual_sparsity:.2f}%\")\n",
    "\n",
    "# Show new architecture\n",
    "print(f\"\\nüèóÔ∏è Network Architecture:\")\n",
    "linear_layers = [m for m in spinn_model.modules() if isinstance(m, nn.Linear)]\n",
    "dims = [layer.in_features for layer in linear_layers] + [linear_layers[-1].out_features]\n",
    "print(f\"   {' ‚Üí '.join(map(str, dims))}\")\n",
    "\n",
    "print(f\"\\nLayer-wise:\")\n",
    "for i, layer in enumerate(linear_layers):\n",
    "    params = layer.weight.numel() + (layer.bias.numel() if layer.bias is not None else 0)\n",
    "    print(f\"   Layer {i}: [{layer.in_features:>3} ‚Üí {layer.out_features:>3}] = {params:,} params\")\n",
    "\n",
    "# Evaluate accuracy\n",
    "spinn_model.eval()\n",
    "with torch.no_grad():\n",
    "    val_pred = spinn_model(X_val_tensor)\n",
    "    val_loss = pinn_loss(val_pred, y_val_tensor)\n",
    "    val_r2 = r2_score(y_val_tensor.cpu().numpy(), val_pred.cpu().numpy())\n",
    "\n",
    "print(f\"\\nüìà Validation Performance:\")\n",
    "print(f\"   Loss: {val_loss.item():.6f}\")\n",
    "print(f\"   R¬≤ Score: {val_r2:.4f}\")\n",
    "\n",
    "# Save model\n",
    "save_path = '/home/jupyter-ksenthilkumar/SPINN/models/saved/spinn_structured.pth'\n",
    "torch.save(spinn_model, save_path)\n",
    "print(f\"\\nüíæ Model saved: {save_path}\")\n",
    "print(f\"\\n{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92a2b07",
   "metadata": {},
   "source": [
    "## Cell 6: Convert to SparsePINN Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a1267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to SparsePINN wrapper\n",
    "sparse_spinn = convert_dense_to_sparse(spinn_model).to(device)\n",
    "\n",
    "# Enable torch.compile() for extra optimization\n",
    "if hasattr(torch, 'compile'):\n",
    "    compiled = sparse_spinn.enable_compile(mode='reduce-overhead')\n",
    "    if compiled:\n",
    "        print(\"‚úÖ torch.compile() enabled (PyTorch 2.0+)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è torch.compile() not available (PyTorch < 2.0)\")\n",
    "\n",
    "# Statistics\n",
    "total, nnz, sparsity = sparse_spinn.count_parameters()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"SPARSE SPINN MODEL\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nüìä Parameters:\")\n",
    "print(f\"   Total: {total:,}\")\n",
    "print(f\"   Non-zero: {nnz:,}\")\n",
    "print(f\"   Sparsity: {sparsity:.2f}%\")\n",
    "\n",
    "print(f\"\\nüèóÔ∏è Architecture:\")\n",
    "for info in sparse_spinn.get_sparsity_info():\n",
    "    print(f\"   Layer {info['layer']}: {info['shape']} ({info['non_zero_params']:,} params)\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úÖ Ready for benchmarking!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71702167",
   "metadata": {},
   "source": [
    "## Cell 7: GPU Benchmark - The Moment of Truth! üöÄ\n",
    "\n",
    "**Expected results:**\n",
    "- Dense PINN: ~0.36 ms\n",
    "- Structured SPINN: ~0.12-0.15 ms\n",
    "- **Speedup: 2.4-3.0x** ‚úÖ\n",
    "\n",
    "If you see <2x speedup, check troubleshooting in guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791f344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark configuration\n",
    "n_trials = 100\n",
    "warmup = 20\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"GPU INFERENCE BENCHMARK\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"   Trials: {n_trials}\")\n",
    "print(f\"   Warmup: {warmup}\")\n",
    "print(f\"   Batch size: {X_val_tensor.shape[0]}\")\n",
    "\n",
    "# ============================================================\n",
    "# DENSE PINN BENCHMARK\n",
    "# ============================================================\n",
    "print(f\"\\nüîµ Benchmarking Dense PINN...\")\n",
    "\n",
    "dense_model.eval()\n",
    "\n",
    "# Warmup\n",
    "for _ in range(warmup):\n",
    "    with torch.no_grad():\n",
    "        _ = dense_model(X_val_tensor)\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# Benchmark\n",
    "dense_times = []\n",
    "for _ in range(n_trials):\n",
    "    torch.cuda.synchronize()\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    \n",
    "    start.record()\n",
    "    with torch.no_grad():\n",
    "        _ = dense_model(X_val_tensor)\n",
    "    end.record()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    dense_times.append(start.elapsed_time(end))\n",
    "\n",
    "dense_mean = np.mean(dense_times)\n",
    "dense_std = np.std(dense_times)\n",
    "\n",
    "print(f\"   ‚úì {dense_mean:.2f} ¬± {dense_std:.2f} ms\")\n",
    "\n",
    "# ============================================================\n",
    "# STRUCTURED SPINN BENCHMARK\n",
    "# ============================================================\n",
    "print(f\"\\nüü¢ Benchmarking Structured SPINN...\")\n",
    "\n",
    "sparse_spinn.eval()\n",
    "\n",
    "# Warmup (important for compiled models)\n",
    "for _ in range(warmup):\n",
    "    with torch.no_grad():\n",
    "        _ = sparse_spinn(X_val_tensor)\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# Benchmark\n",
    "sparse_times = []\n",
    "for _ in range(n_trials):\n",
    "    torch.cuda.synchronize()\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    \n",
    "    start.record()\n",
    "    with torch.no_grad():\n",
    "        _ = sparse_spinn(X_val_tensor)\n",
    "    end.record()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    sparse_times.append(start.elapsed_time(end))\n",
    "\n",
    "sparse_mean = np.mean(sparse_times)\n",
    "sparse_std = np.std(sparse_times)\n",
    "\n",
    "print(f\"   ‚úì {sparse_mean:.2f} ¬± {sparse_std:.2f} ms\")\n",
    "\n",
    "# ============================================================\n",
    "# RESULTS\n",
    "# ============================================================\n",
    "speedup = dense_mean / sparse_mean\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üìä BENCHMARK RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nDense PINN:         {dense_mean:.2f} ¬± {dense_std:.2f} ms\")\n",
    "print(f\"Structured SPINN:   {sparse_mean:.2f} ¬± {sparse_std:.2f} ms\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚ö° GPU SPEEDUP:      {speedup:.2f}x\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Theoretical analysis\n",
    "dense_params = sum(p.numel() for p in dense_model.parameters())\n",
    "sparse_params = sum(p.numel() for p in sparse_spinn.parameters())\n",
    "param_ratio = dense_params / sparse_params\n",
    "\n",
    "print(f\"\\nüìê Theoretical Analysis:\")\n",
    "print(f\"   Dense parameters:    {dense_params:,}\")\n",
    "print(f\"   Sparse parameters:   {sparse_params:,}\")\n",
    "print(f\"   Parameter ratio:     {param_ratio:.2f}x\")\n",
    "print(f\"   Measured speedup:    {speedup:.2f}x\")\n",
    "print(f\"   Efficiency:          {(speedup/param_ratio)*100:.1f}%\")\n",
    "\n",
    "# Success assessment\n",
    "print(f\"\\n{'='*60}\")\n",
    "if speedup >= 2.0:\n",
    "    print(f\"‚úÖ SUCCESS! Achieved {speedup:.2f}x speedup\")\n",
    "    print(f\"   Target was 2-3x - YOU DID IT! üéâ\")\n",
    "    print(f\"\\n   Next steps:\")\n",
    "    print(f\"   1. Run CPU benchmark (Cell 8)\")\n",
    "    print(f\"   2. Generate figures\")\n",
    "    print(f\"   3. Update paper\")\n",
    "elif speedup >= 1.5:\n",
    "    print(f\"‚ö†Ô∏è PARTIAL SUCCESS: {speedup:.2f}x speedup\")\n",
    "    print(f\"   Close to target (2-3x)\")\n",
    "    print(f\"\\n   Try:\")\n",
    "    print(f\"   - sparse_spinn.enable_compile(mode='max-autotune')\")\n",
    "    print(f\"   - Check layer dimensions actually changed\")\n",
    "else:\n",
    "    print(f\"‚ùå UNEXPECTED: Only {speedup:.2f}x speedup\")\n",
    "    print(f\"\\n   Troubleshooting:\")\n",
    "    print(f\"   1. Check layer dimensions:\")\n",
    "    print(f\"      for layer in spinn_model.modules():\")\n",
    "    print(f\"          if isinstance(layer, nn.Linear):\")\n",
    "    print(f\"              print(f'[{{layer.in_features}} ‚Üí {{layer.out_features}}]')\")\n",
    "    print(f\"\\n   2. Should see smaller dimensions (e.g., 256 not 512)\")\n",
    "    print(f\"\\n   3. If dimensions same, structured pruning didn't work\")\n",
    "\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e33b0f2",
   "metadata": {},
   "source": [
    "## Cell 8: CPU Benchmark (Optional)\n",
    "\n",
    "Test on CPU to show speedup across different hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Move models to CPU\n",
    "dense_cpu = dense_model.cpu()\n",
    "sparse_cpu = sparse_spinn.cpu()\n",
    "X_val_cpu = X_val_tensor.cpu()\n",
    "\n",
    "n_trials = 100\n",
    "warmup = 10\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"CPU INFERENCE BENCHMARK\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Dense benchmark\n",
    "print(f\"\\nüîµ Dense PINN...\")\n",
    "dense_cpu.eval()\n",
    "\n",
    "for _ in range(warmup):\n",
    "    _ = dense_cpu(X_val_cpu)\n",
    "\n",
    "dense_times = []\n",
    "for _ in range(n_trials):\n",
    "    start = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        _ = dense_cpu(X_val_cpu)\n",
    "    end = time.perf_counter()\n",
    "    dense_times.append((end - start) * 1000)\n",
    "\n",
    "dense_cpu_mean = np.mean(dense_times)\n",
    "print(f\"   {dense_cpu_mean:.2f} ms\")\n",
    "\n",
    "# Sparse benchmark\n",
    "print(f\"\\nüü¢ Structured SPINN...\")\n",
    "sparse_cpu.eval()\n",
    "\n",
    "for _ in range(warmup):\n",
    "    _ = sparse_cpu(X_val_cpu)\n",
    "\n",
    "sparse_times = []\n",
    "for _ in range(n_trials):\n",
    "    start = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        _ = sparse_cpu(X_val_cpu)\n",
    "    end = time.perf_counter()\n",
    "    sparse_times.append((end - start) * 1000)\n",
    "\n",
    "sparse_cpu_mean = np.mean(sparse_times)\n",
    "print(f\"   {sparse_cpu_mean:.2f} ms\")\n",
    "\n",
    "cpu_speedup = dense_cpu_mean / sparse_cpu_mean\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚ö° CPU SPEEDUP: {cpu_speedup:.2f}x\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Move back to GPU\n",
    "dense_model = dense_cpu.to(device)\n",
    "sparse_spinn = sparse_cpu.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e0939a",
   "metadata": {},
   "source": [
    "## Cell 9: Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b6fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate both models on test set\n",
    "dense_model.eval()\n",
    "sparse_spinn.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Dense predictions\n",
    "    dense_pred = dense_model(X_test_tensor)\n",
    "    dense_test_r2 = r2_score(y_test_tensor.cpu().numpy(), dense_pred.cpu().numpy())\n",
    "    dense_test_mse = mean_squared_error(y_test_tensor.cpu().numpy(), dense_pred.cpu().numpy())\n",
    "    \n",
    "    # Sparse predictions\n",
    "    sparse_pred = sparse_spinn(X_test_tensor)\n",
    "    sparse_test_r2 = r2_score(y_test_tensor.cpu().numpy(), sparse_pred.cpu().numpy())\n",
    "    sparse_test_mse = mean_squared_error(y_test_tensor.cpu().numpy(), sparse_pred.cpu().numpy())\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"TEST SET EVALUATION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nDense PINN:\")\n",
    "print(f\"   R¬≤ Score: {dense_test_r2:.4f}\")\n",
    "print(f\"   MSE: {dense_test_mse:.6f}\")\n",
    "print(f\"\\nStructured SPINN:\")\n",
    "print(f\"   R¬≤ Score: {sparse_test_r2:.4f}\")\n",
    "print(f\"   MSE: {sparse_test_mse:.6f}\")\n",
    "print(f\"\\nImprovement:\")\n",
    "print(f\"   ŒîR¬≤: {sparse_test_r2 - dense_test_r2:+.4f}\")\n",
    "print(f\"   {'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164caf61",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Run this cell to see complete results table for your paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce588d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results summary\n",
    "results = {\n",
    "    'Model': ['Dense PINN', 'SPINN (Structured)'],\n",
    "    'Parameters': [dense_params, sparse_params],\n",
    "    'GPU Time (ms)': [f\"{dense_mean:.2f}\", f\"{sparse_mean:.2f}\"],\n",
    "    'GPU Speedup': [\"1.0x\", f\"{speedup:.2f}x\"],\n",
    "    'Test R¬≤': [f\"{dense_test_r2:.4f}\", f\"{sparse_test_r2:.4f}\"]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"FINAL RESULTS - COPY THIS TO YOUR PAPER\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "print(results_df.to_string(index=False))\n",
    "print(f\"\\n{'='*80}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Key Achievements:\")\n",
    "print(f\"   ‚Ä¢ Parameter reduction: {(1-sparse_params/dense_params)*100:.1f}%\")\n",
    "print(f\"   ‚Ä¢ GPU speedup: {speedup:.2f}x\")\n",
    "print(f\"   ‚Ä¢ Accuracy improvement: {sparse_test_r2 - dense_test_r2:+.4f} R¬≤\")\n",
    "print(f\"\\nüéâ CONGRATULATIONS! Your abstract claims are now supported!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

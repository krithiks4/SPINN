{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78eb7db9",
   "metadata": {},
   "source": [
    "# SPINN Complete Workflow - Jupyter Lab\n",
    "## End-to-End Training and Benchmarking\n",
    "\n",
    "**Total Time**: ~2.5-3 hours  \n",
    "**Goal**: Train Dense PINN + SPINN, convert to sparse tensors, benchmark, and generate results\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Workflow Steps:\n",
    "1. **Setup & Check GPU** (5 min)\n",
    "2. **Data Preprocessing** (5 min)\n",
    "3. **Train Baseline** (30-40 min)\n",
    "4. **Train SPINN** (60-90 min) ‚è∞ Longest step!\n",
    "5. **Load Models** (1 min)\n",
    "6. **Convert to Sparse Tensors** (10 min) üî• Critical!\n",
    "7. **GPU Benchmarking** (5 min)\n",
    "8. **CPU Benchmarking** (5 min)\n",
    "9. **Test Evaluation** (5 min)\n",
    "10. **Generate Figures** (3 min)\n",
    "\n",
    "---\n",
    "\n",
    "**‚ö†Ô∏è Important Notes:**\n",
    "- Run cells in order (don't skip!)\n",
    "- Check for ‚úÖ success messages after each major step\n",
    "- Cell 3 (SPINN training) is longest - be patient!\n",
    "- Cell 6 (sparse conversion) is critical for publishable speedup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0837137",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 1: Setup & Check GPU (5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ENVIRONMENT SETUP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check PyTorch version\n",
    "print(f\"\\n‚úÖ PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check CUDA availability\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"‚úÖ CUDA available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected - will use CPU (training will be slower)\")\n",
    "    print(\"üí° CPU-only training is fine but will take 3-5x longer\")\n",
    "    device = 'cpu'\n",
    "\n",
    "# Check current directory\n",
    "print(f\"\\nüìÅ Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Verify key files exist\n",
    "key_files = [\n",
    "    'data/preprocess.py',\n",
    "    'train_baseline_simple.py',\n",
    "    'train_spinn.py',\n",
    "    'convert_to_sparse.py',\n",
    "    'models/dense_pinn.py',\n",
    "    'models/sparse_pinn.py'\n",
    "]\n",
    "\n",
    "print(\"\\nüîç Checking key files:\")\n",
    "all_present = True\n",
    "for file in key_files:\n",
    "    exists = os.path.exists(file)\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"   {status} {file}\")\n",
    "    if not exists:\n",
    "        all_present = False\n",
    "\n",
    "if all_present:\n",
    "    print(\"\\n‚úÖ All files present - ready to start!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Some files missing - check repository structure\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository and setup environment\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"REPOSITORY SETUP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get home directory\n",
    "home_dir = os.path.expanduser('~')\n",
    "repo_path = os.path.join(home_dir, 'SPINN_ASME')\n",
    "\n",
    "# Clone repository if it doesn't exist\n",
    "if not os.path.exists(repo_path):\n",
    "    print(f\"\\nüì• Cloning repository to {repo_path}...\")\n",
    "    result = subprocess.run([\n",
    "        'git', 'clone', \n",
    "        'https://github.com/krithiks4/SPINN.git',\n",
    "        repo_path\n",
    "    ], capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ Repository cloned successfully!\")\n",
    "    else:\n",
    "        print(f\"‚ùå Clone failed: {result.stderr}\")\n",
    "        print(\"\\n\udca1 Trying with authentication token...\")\n",
    "        result = subprocess.run([\n",
    "            'git', 'clone',\n",
    "            'https://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@github.com/krithiks4/SPINN.git',\n",
    "            repo_path\n",
    "        ], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"‚úÖ Repository cloned with token!\")\n",
    "        else:\n",
    "            print(f\"‚ùå Still failed: {result.stderr}\")\n",
    "            sys.exit(1)\n",
    "else:\n",
    "    print(f\"‚úÖ Repository already exists at {repo_path}\")\n",
    "\n",
    "# Change to repository directory\n",
    "os.chdir(repo_path)\n",
    "print(f\"‚úÖ Changed to: {os.getcwd()}\")\n",
    "\n",
    "# Pull latest changes\n",
    "print(\"\\nüì• Pulling latest changes...\")\n",
    "result = subprocess.run(['git', 'pull', 'origin', 'main'], \n",
    "                       capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "\n",
    "# Show recent commits\n",
    "print(\"\\nüìú Recent commits:\")\n",
    "result = subprocess.run(['git', 'log', '--oneline', '-3'], \n",
    "                       capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "\n",
    "# Configure git\n",
    "print(\"\\n‚öôÔ∏è Configuring git...\")\n",
    "subprocess.run(['git', 'config', '--global', 'user.email', 'krithiks4@gmail.com'])\n",
    "subprocess.run(['git', 'config', '--global', 'user.name', 'krithiks4'])\n",
    "print(\"‚úÖ Git configured!\")\n",
    "\n",
    "# Install requirements if needed\n",
    "print(\"\\nüì¶ Checking dependencies...\")\n",
    "if os.path.exists('requirements.txt'):\n",
    "    print(\"Installing requirements...\")\n",
    "    result = subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-r', 'requirements.txt'],\n",
    "                          capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ Requirements installed!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Some packages may have failed, but continuing...\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No requirements.txt found, skipping...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ SETUP COMPLETE!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c9974",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 2: Data Preprocessing (5 min)\n",
    "\n",
    "This creates train/val/test splits with proper data leakage checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce4b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Run preprocessing\n",
    "print(\"\\nüîÑ Running preprocessing script...\")\n",
    "result = subprocess.run(['python', 'data/preprocess.py'], capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "if result.returncode != 0:\n",
    "    print(f\"‚ö†Ô∏è  Error: {result.stderr}\")\n",
    "\n",
    "# Verify splits\n",
    "with open('data/processed/metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA SPLITS VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train samples: {metadata['train_samples']}\")\n",
    "print(f\"Val samples:   {metadata['val_samples']}\")\n",
    "print(f\"Test samples:  {metadata['test_samples']}\")\n",
    "print(f\"Total:         {metadata['train_samples'] + metadata['val_samples'] + metadata['test_samples']}\")\n",
    "\n",
    "# Load and check for data leakage\n",
    "train = pd.read_csv('data/processed/train.csv')\n",
    "val = pd.read_csv('data/processed/val.csv')\n",
    "test = pd.read_csv('data/processed/test.csv')\n",
    "\n",
    "# Check actual data overlap using unique identifiers\n",
    "def get_unique_keys(df):\n",
    "    \"\"\"Create unique keys for each row\"\"\"\n",
    "    return set(df['experiment_id'].astype(str) + '_' + \n",
    "               df['case_index'].astype(str) + '_' + \n",
    "               df['time'].astype(str))\n",
    "\n",
    "train_keys = get_unique_keys(train)\n",
    "val_keys = get_unique_keys(val)\n",
    "test_keys = get_unique_keys(test)\n",
    "\n",
    "overlap_train_val = len(train_keys & val_keys)\n",
    "overlap_train_test = len(train_keys & test_keys)\n",
    "overlap_val_test = len(val_keys & test_keys)\n",
    "\n",
    "print(f\"\\nüîç Data Leakage Check:\")\n",
    "print(f\"Train-Val overlap:  {overlap_train_val} (should be 0)\")\n",
    "print(f\"Train-Test overlap: {overlap_train_test} (should be 0)\")\n",
    "print(f\"Val-Test overlap:   {overlap_val_test} (should be 0)\")\n",
    "\n",
    "if overlap_train_val == 0 and overlap_train_test == 0 and overlap_val_test == 0:\n",
    "    print(\"\\n‚úÖ No data leakage detected!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è WARNING: Data leakage detected!\")\n",
    "\n",
    "print(\"\\n‚úÖ Preprocessing complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf97813f",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 3: Train Baseline Dense PINN (30-40 min)\n",
    "\n",
    "**Note**: No dropout or L2 regularization - this is intentional!  \n",
    "We want to show pruning acts as implicit regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb61224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING DENSE PINN BASELINE\")\n",
    "print(\"=\"*60)\n",
    "print(\"Configuration:\")\n",
    "print(\"  - Architecture: [512, 512, 512, 256]\")\n",
    "print(\"  - Random seed: 42\")\n",
    "print(\"  - Early stopping: Yes (patience=10)\")\n",
    "print(\"  - No dropout or L2 regularization\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìù NOTE: We intentionally train baseline WITHOUT extra regularization\")\n",
    "print(\"   to show pruning's regularization effect. This is standard practice\")\n",
    "print(\"   in neural network pruning research.\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Run training\n",
    "print(\"\\nüîÑ Starting training...\\n\")\n",
    "result = subprocess.run(['python', 'train_baseline_simple.py'], \n",
    "                       capture_output=False, text=True)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(f\"\\n‚úÖ Baseline training complete! ({elapsed/60:.1f} minutes)\")\n",
    "    print(\"\\nüìä Expected: Test R¬≤ around 0.4-0.5 (overfitting without regularization)\")\n",
    "    print(\"   This demonstrates pruning's implicit regularization benefit!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Training failed with exit code {result.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0665ef8f",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 4: Train SPINN (60-90 min) ‚è∞ LONGEST STEP\n",
    "\n",
    "**‚è∞ Good time for a break!**  \n",
    "This does iterative magnitude pruning (4 stages) with fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fafc90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING SPINN (PRUNING + FINE-TUNING)\")\n",
    "print(\"=\"*60)\n",
    "print(\"This will:\")\n",
    "print(\"  1. Load dense baseline model\")\n",
    "print(\"  2. Iteratively prune to 68.5% sparsity (4 stages)\")\n",
    "print(\"  3. Fine-tune after each pruning stage\")\n",
    "print(\"  4. Save final sparse model\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚è∞ Expected time: 60-90 minutes\")\n",
    "print(\"üí° Perfect time for a coffee break!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Run SPINN training\n",
    "print(\"\\nüîÑ Starting SPINN training...\\n\")\n",
    "result = subprocess.run(['python', 'train_spinn.py'], \n",
    "                       capture_output=False, text=True)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(f\"\\n‚úÖ SPINN training complete! ({elapsed/60:.1f} minutes)\")\n",
    "    print(\"\\nüìä Expected: Test R¬≤ around 0.85-0.90 with 68.5% sparsity\")\n",
    "    print(\"   Huge improvement over baseline!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Training failed with exit code {result.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba57ae30",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 5: Load Models & Verify Parameters (1 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2327e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('models')\n",
    "from dense_pinn import DensePINN\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load models\n",
    "print(\"\\nüì• Loading models...\")\n",
    "dense_model = DensePINN(input_dim=18, hidden_dims=[512,512,512,256], output_dim=2).to(device)\n",
    "dense_model.load_state_dict(torch.load('results/checkpoints/dense_pinn_final.pt', map_location=device))\n",
    "\n",
    "spinn_model = DensePINN(input_dim=18, hidden_dims=[512,512,512,256], output_dim=2).to(device)\n",
    "spinn_model.load_state_dict(torch.load('results/checkpoints/spinn_final.pt', map_location=device))\n",
    "\n",
    "# Count parameters\n",
    "def count_parameters(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    nonzero = sum(torch.count_nonzero(p).item() for p in model.parameters())\n",
    "    return total, nonzero\n",
    "\n",
    "dense_total, dense_nonzero = count_parameters(dense_model)\n",
    "spinn_total, spinn_nonzero = count_parameters(spinn_model)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PARAMETER VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dense PINN: {dense_nonzero:,} parameters\")\n",
    "print(f\"SPINN:      {spinn_nonzero:,} parameters (dense storage)\")\n",
    "print(f\"Reduction:  {(1 - spinn_nonzero/dense_nonzero)*100:.1f}%\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚ö†Ô∏è  NOTE: SPINN still uses dense storage (stores zeros)\")\n",
    "print(\"   Next step converts to TRUE sparse tensors for speedup!\")\n",
    "\n",
    "# Save for later use\n",
    "dense_params = dense_nonzero\n",
    "spinn_params = spinn_nonzero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91218db",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 6: Convert to Sparse Tensors (10 min) üî• CRITICAL\n",
    "\n",
    "**This is the key to getting publishable 2-3x speedup!**  \n",
    "Converts from dense storage (zeros stored) to sparse COO format (zeros skipped)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9f1611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CONVERTING SPINN TO SPARSE TENSOR FORMAT\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚ö†Ô∏è  CRITICAL: This converts to TRUE sparse operations\")\n",
    "print(\"   - torch.nn.utils.prune: Creates masks but stores as DENSE\")\n",
    "print(\"   - torch.sparse_coo_tensor: Stores only non-zero values\")\n",
    "print(\"   - Result: 2-3x GPU speedup, 2-4x CPU speedup\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Run conversion script\n",
    "print(\"\\nüîÑ Running sparse conversion...\\n\")\n",
    "result = subprocess.run(['python', 'convert_to_sparse.py'], \n",
    "                       capture_output=False, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    # Load sparse model\n",
    "    print(\"\\nüì• Loading sparse model...\")\n",
    "    from sparse_pinn import SparsePINN\n",
    "    \n",
    "    checkpoint = torch.load('results/checkpoints/spinn_sparse_final.pt', map_location=device)\n",
    "    spinn_sparse_model = checkpoint['model'].to(device)\n",
    "    \n",
    "    sparse_total, sparse_nonzero, sparse_sparsity = spinn_sparse_model.count_parameters()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SPARSE MODEL LOADED\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total parameters:     {sparse_total:,}\")\n",
    "    print(f\"Non-zero parameters:  {sparse_nonzero:,}\")\n",
    "    print(f\"Sparsity:             {sparse_sparsity:.1f}%\")\n",
    "    print(f\"Storage format:       torch.sparse_coo_tensor\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\n‚úÖ Ready for benchmarking with TRUE sparse operations!\")\n",
    "    print(\"   Expected: 2-3x GPU speedup, 2-4x CPU speedup\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Conversion failed with exit code {result.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445d7705",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 7: GPU Benchmarking (5 min)\n",
    "\n",
    "**Success criteria**: Speedup ‚â• 2.0x for publishable results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b342ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BATCH INFERENCE BENCHMARKING (GPU)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create dummy batch\n",
    "batch_size = 1000\n",
    "if torch.cuda.is_available():\n",
    "    X_dummy = torch.randn(batch_size, 18).cuda()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected - skipping GPU benchmark\")\n",
    "    print(\"   Will benchmark on CPU in next cell\")\n",
    "    batch_results_gpu = None\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dense_model.eval()\n",
    "    spinn_sparse_model.eval()\n",
    "    \n",
    "    # Warmup (important for GPU timing accuracy)\n",
    "    print(\"\\nüî• Warming up GPU...\")\n",
    "    for _ in range(10):\n",
    "        _ = dense_model(X_dummy)\n",
    "        _ = spinn_sparse_model(X_dummy)\n",
    "    \n",
    "    # Benchmark Dense PINN\n",
    "    print(\"‚è±Ô∏è  Benchmarking Dense PINN (100 iterations)...\")\n",
    "    torch.cuda.synchronize()\n",
    "    dense_times = []\n",
    "    for _ in range(100):\n",
    "        start = time.time()\n",
    "        with torch.no_grad():\n",
    "            _ = dense_model(X_dummy)\n",
    "        torch.cuda.synchronize()\n",
    "        dense_times.append((time.time() - start) * 1000)\n",
    "    \n",
    "    # Benchmark Sparse SPINN\n",
    "    print(\"‚è±Ô∏è  Benchmarking Sparse SPINN (100 iterations)...\")\n",
    "    torch.cuda.synchronize()\n",
    "    spinn_times = []\n",
    "    for _ in range(100):\n",
    "        start = time.time()\n",
    "        with torch.no_grad():\n",
    "            _ = spinn_sparse_model(X_dummy)\n",
    "        torch.cuda.synchronize()\n",
    "        spinn_times.append((time.time() - start) * 1000)\n",
    "    \n",
    "    dense_mean_gpu = np.mean(dense_times)\n",
    "    dense_std_gpu = np.std(dense_times)\n",
    "    spinn_mean_gpu = np.mean(spinn_times)\n",
    "    spinn_std_gpu = np.std(spinn_times)\n",
    "    speedup_gpu = dense_mean_gpu / spinn_mean_gpu\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GPU BATCH INFERENCE RESULTS (1000 samples)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Dense PINN:   {dense_mean_gpu:.2f} ¬± {dense_std_gpu:.2f} ms\")\n",
    "    print(f\"Sparse SPINN: {spinn_mean_gpu:.2f} ¬± {spinn_std_gpu:.2f} ms\")\n",
    "    print(f\"üöÄ Speedup:   {speedup_gpu:.2f}x\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if speedup_gpu >= 2.0:\n",
    "        print(\"\\n‚úÖ EXCELLENT: 2x+ speedup achieved! Publishable!\")\n",
    "    elif speedup_gpu >= 1.5:\n",
    "        print(\"\\n‚úÖ GOOD: Speedup in acceptable range!\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  WARNING: Speedup lower than expected\")\n",
    "        print(\"   Check that sparse conversion completed successfully\")\n",
    "    \n",
    "    batch_results_gpu = {\n",
    "        'dense_mean_ms': float(dense_mean_gpu),\n",
    "        'dense_std_ms': float(dense_std_gpu),\n",
    "        'spinn_mean_ms': float(spinn_mean_gpu),\n",
    "        'spinn_std_ms': float(spinn_std_gpu),\n",
    "        'speedup': float(speedup_gpu),\n",
    "        'device': 'GPU',\n",
    "        'storage_format': 'torch.sparse_coo_tensor'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d41430",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 8: CPU Benchmarking (5 min)\n",
    "\n",
    "**Success criteria**: Speedup ‚â• 2.5x validates edge deployment claims!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b82df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BATCH INFERENCE BENCHMARKING (CPU)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüí° CPU benchmarking validates edge deployment claims\")\n",
    "print(\"   Sparse operations typically 2-4x faster on CPU than GPU\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Move models to CPU\n",
    "print(\"\\nüì¶ Moving models to CPU...\")\n",
    "dense_model_cpu = dense_model.cpu()\n",
    "spinn_sparse_model_cpu = spinn_sparse_model.cpu()\n",
    "\n",
    "# Create dummy batch on CPU\n",
    "X_dummy_cpu = torch.randn(batch_size, 18)\n",
    "\n",
    "# Warmup CPU\n",
    "print(\"üî• Warming up CPU...\")\n",
    "for _ in range(10):\n",
    "    _ = dense_model_cpu(X_dummy_cpu)\n",
    "    _ = spinn_sparse_model_cpu(X_dummy_cpu)\n",
    "\n",
    "# Benchmark Dense PINN on CPU\n",
    "print(\"\\n‚è±Ô∏è  Benchmarking Dense PINN on CPU (100 iterations)...\")\n",
    "dense_times_cpu = []\n",
    "for _ in range(100):\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        _ = dense_model_cpu(X_dummy_cpu)\n",
    "    dense_times_cpu.append((time.time() - start) * 1000)\n",
    "\n",
    "# Benchmark Sparse SPINN on CPU\n",
    "print(\"‚è±Ô∏è  Benchmarking Sparse SPINN on CPU (100 iterations)...\")\n",
    "spinn_times_cpu = []\n",
    "for _ in range(100):\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        _ = spinn_sparse_model_cpu(X_dummy_cpu)\n",
    "    spinn_times_cpu.append((time.time() - start) * 1000)\n",
    "\n",
    "dense_mean_cpu = np.mean(dense_times_cpu)\n",
    "dense_std_cpu = np.std(dense_times_cpu)\n",
    "spinn_mean_cpu = np.mean(spinn_times_cpu)\n",
    "spinn_std_cpu = np.std(spinn_times_cpu)\n",
    "speedup_cpu = dense_mean_cpu / spinn_mean_cpu\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CPU BATCH INFERENCE RESULTS (1000 samples)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dense PINN:   {dense_mean_cpu:.2f} ¬± {dense_std_cpu:.2f} ms\")\n",
    "print(f\"Sparse SPINN: {spinn_mean_cpu:.2f} ¬± {spinn_std_cpu:.2f} ms\")\n",
    "print(f\"üöÄ Speedup:    {speedup_cpu:.2f}x\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if batch_results_gpu is not None:\n",
    "    print(f\"\\nüìä CPU vs GPU Speedup Comparison:\")\n",
    "    print(f\"   GPU speedup: {batch_results_gpu['speedup']:.2f}x\")\n",
    "    print(f\"   CPU speedup: {speedup_cpu:.2f}x\")\n",
    "    print(f\"   CPU advantage: {speedup_cpu/batch_results_gpu['speedup']:.2f}x higher\")\n",
    "\n",
    "if speedup_cpu >= 3.0:\n",
    "    print(\"\\n‚úÖ EXCELLENT: ‚â•3x CPU speedup validates edge deployment!\")\n",
    "elif speedup_cpu >= 2.0:\n",
    "    print(\"\\n‚úÖ GOOD: CPU speedup validates edge deployment feasibility!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: CPU speedup lower than expected\")\n",
    "\n",
    "batch_results_cpu = {\n",
    "    'dense_mean_ms': float(dense_mean_cpu),\n",
    "    'dense_std_ms': float(dense_std_cpu),\n",
    "    'spinn_mean_ms': float(spinn_mean_cpu),\n",
    "    'spinn_std_ms': float(spinn_std_cpu),\n",
    "    'speedup': float(speedup_cpu),\n",
    "    'device': 'CPU',\n",
    "    'storage_format': 'torch.sparse_coo_tensor'\n",
    "}\n",
    "\n",
    "# Move models back to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    dense_model = dense_model.cuda()\n",
    "    spinn_sparse_model = spinn_sparse_model.cuda()\n",
    "    print(\"\\n‚úÖ Models moved back to GPU for test evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce33e50b",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 9: Test Set Evaluation (5 min)\n",
    "\n",
    "Generate predictions and calculate final metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1079d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_csv('data/processed/test.csv')\n",
    "with open('data/processed/metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "input_features = [f for f in metadata['feature_names'] \n",
    "                 if f not in ['tool_wear', 'thermal_displacement']]\n",
    "output_features = ['tool_wear', 'thermal_displacement']\n",
    "\n",
    "X_test = torch.FloatTensor(test_data[input_features].values).to(device)\n",
    "y_test = torch.FloatTensor(test_data[output_features].values).to(device)\n",
    "\n",
    "# Generate predictions from both models\n",
    "dense_model.eval()\n",
    "spinn_sparse_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred_dense = dense_model(X_test).cpu().numpy()\n",
    "    y_pred_spinn = spinn_sparse_model(X_test).cpu().numpy()\n",
    "\n",
    "y_test_np = y_test.cpu().numpy()\n",
    "\n",
    "# Calculate metrics\n",
    "metrics_comparison = {'dense': {}, 'spinn': {}}\n",
    "\n",
    "for model_name, y_pred in [('dense', y_pred_dense), ('spinn', y_pred_spinn)]:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name.upper()} PINN TEST METRICS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Overall\n",
    "    overall_r2 = r2_score(y_test_np, y_pred)\n",
    "    overall_rmse = np.sqrt(mean_squared_error(y_test_np, y_pred))\n",
    "    \n",
    "    print(f\"\\nüìä OVERALL:\")\n",
    "    print(f\"   R¬≤:   {overall_r2:.4f}\")\n",
    "    print(f\"   RMSE: {overall_rmse:.6f}\")\n",
    "    \n",
    "    metrics_comparison[model_name]['overall'] = {\n",
    "        'r2': float(overall_r2),\n",
    "        'rmse': float(overall_rmse)\n",
    "    }\n",
    "    \n",
    "    # Per-output metrics\n",
    "    metrics_comparison[model_name]['per_output'] = {}\n",
    "    \n",
    "    for i, output_name in enumerate(output_features):\n",
    "        y_true = y_test_np[:, i]\n",
    "        y_pred_i = y_pred[:, i]\n",
    "        \n",
    "        r2 = r2_score(y_true, y_pred_i)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred_i))\n",
    "        mae = mean_absolute_error(y_true, y_pred_i)\n",
    "        \n",
    "        # MAPE only for tool wear\n",
    "        if output_name == 'tool_wear':\n",
    "            mask = np.abs(y_true) > 1e-6\n",
    "            mape = np.mean(np.abs((y_true[mask] - y_pred_i[mask]) / y_true[mask])) * 100\n",
    "        else:\n",
    "            mape = None  # Don't calculate MAPE for thermal\n",
    "        \n",
    "        print(f\"\\nüìä {output_name.upper()}:\")\n",
    "        print(f\"   R¬≤:   {r2:.4f}\")\n",
    "        print(f\"   RMSE: {rmse:.6f}\")\n",
    "        print(f\"   MAE:  {mae:.6f}\")\n",
    "        if mape is not None:\n",
    "            print(f\"   MAPE: {mape:.2f}%\")\n",
    "        else:\n",
    "            print(f\"   MAPE: N/A (not meaningful for small values)\")\n",
    "        \n",
    "        metrics_comparison[model_name]['per_output'][output_name] = {\n",
    "            'r2': float(r2),\n",
    "            'rmse': float(rmse),\n",
    "            'mae': float(mae),\n",
    "            'mape': float(mape) if mape is not None else None\n",
    "        }\n",
    "\n",
    "# Add benchmarking results\n",
    "metrics_comparison['benchmarking'] = {\n",
    "    'gpu': batch_results_gpu,\n",
    "    'cpu': batch_results_cpu\n",
    "}\n",
    "\n",
    "# Save results\n",
    "import os\n",
    "os.makedirs('results/benchmarks', exist_ok=True)\n",
    "\n",
    "with open('results/benchmarks/metrics_comparison.json', 'w') as f:\n",
    "    json.dump(metrics_comparison, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ Test evaluation complete!\")\n",
    "print(f\"\\nüìä FINAL SUMMARY:\")\n",
    "print(f\"   Dense R¬≤:     {metrics_comparison['dense']['overall']['r2']:.4f}\")\n",
    "print(f\"   Sparse R¬≤:    {metrics_comparison['spinn']['overall']['r2']:.4f}\")\n",
    "if batch_results_gpu is not None:\n",
    "    print(f\"   GPU Speedup:  {batch_results_gpu['speedup']:.2f}x\")\n",
    "print(f\"   CPU Speedup:  {batch_results_cpu['speedup']:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421270cf",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 10: Generate Comparison Figures (3 min)\n",
    "\n",
    "Create publication-ready comparison charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ed56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"GENERATING COMPARISON FIGURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extract metrics\n",
    "dense_r2 = metrics_comparison['dense']['overall']['r2']\n",
    "spinn_r2 = metrics_comparison['spinn']['overall']['r2']\n",
    "\n",
    "dense_tool_r2 = metrics_comparison['dense']['per_output']['tool_wear']['r2']\n",
    "spinn_tool_r2 = metrics_comparison['spinn']['per_output']['tool_wear']['r2']\n",
    "\n",
    "dense_thermal_r2 = metrics_comparison['dense']['per_output']['thermal_displacement']['r2']\n",
    "spinn_thermal_r2 = metrics_comparison['spinn']['per_output']['thermal_displacement']['r2']\n",
    "\n",
    "# Create figure with 3 subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Plot 1: Parameters\n",
    "ax = axes[0]\n",
    "models = ['Dense PINN', 'SPINN']\n",
    "params = [dense_params/1000, spinn_params/1000]\n",
    "colors = ['#3498db', '#e74c3c']\n",
    "\n",
    "bars = ax.bar(models, params, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax.set_ylabel('Parameters (thousands)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Model Size Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, max(params)*1.2)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, val in zip(bars, params):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{val:.0f}k', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "reduction_pct = (1 - spinn_params/dense_params) * 100\n",
    "ax.text(0.5, max(params)*1.1, f'‚Üì {reduction_pct:.1f}%',\n",
    "        ha='center', fontsize=12, fontweight='bold', color='green')\n",
    "\n",
    "# Plot 2: R¬≤ Scores\n",
    "ax = axes[1]\n",
    "x = np.arange(3)\n",
    "width = 0.35\n",
    "\n",
    "r2_dense = [dense_r2, dense_tool_r2, dense_thermal_r2]\n",
    "r2_spinn = [spinn_r2, spinn_tool_r2, spinn_thermal_r2]\n",
    "\n",
    "bars1 = ax.bar(x - width/2, r2_dense, width, label='Dense PINN', \n",
    "               color='#3498db', edgecolor='black', linewidth=1.5)\n",
    "bars2 = ax.bar(x + width/2, r2_spinn, width, label='SPINN',\n",
    "               color='#e74c3c', edgecolor='black', linewidth=1.5)\n",
    "\n",
    "ax.set_ylabel('R¬≤ Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Prediction Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Overall', 'Tool Wear', 'Thermal'], fontsize=10)\n",
    "ax.legend(fontsize=10)\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Plot 3: Inference Time\n",
    "ax = axes[2]\n",
    "x = np.arange(2)\n",
    "width = 0.25\n",
    "\n",
    "if batch_results_gpu is not None:\n",
    "    gpu_times = [batch_results_gpu['dense_mean_ms'], batch_results_gpu['spinn_mean_ms']]\n",
    "    cpu_times = [batch_results_cpu['dense_mean_ms'], batch_results_cpu['spinn_mean_ms']]\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, gpu_times, width, label='GPU', \n",
    "                   color='#2ecc71', edgecolor='black', linewidth=1.5)\n",
    "    bars2 = ax.bar(x + width/2, cpu_times, width, label='CPU',\n",
    "                   color='#f39c12', edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    gpu_speedup = batch_results_gpu['speedup']\n",
    "    cpu_speedup = batch_results_cpu['speedup']\n",
    "    \n",
    "    ax.text(0.5, max(max(gpu_times), max(cpu_times))*0.9,\n",
    "            f'GPU: {gpu_speedup:.2f}x faster',\n",
    "            ha='center', fontsize=10, fontweight='bold', color='#2ecc71')\n",
    "    ax.text(0.5, max(max(gpu_times), max(cpu_times))*0.8,\n",
    "            f'CPU: {cpu_speedup:.2f}x faster',\n",
    "            ha='center', fontsize=10, fontweight='bold', color='#f39c12')\n",
    "else:\n",
    "    # CPU only\n",
    "    cpu_times = [batch_results_cpu['dense_mean_ms'], batch_results_cpu['spinn_mean_ms']]\n",
    "    bars = ax.bar(x, cpu_times, label='CPU',\n",
    "                  color='#f39c12', edgecolor='black', linewidth=1.5)\n",
    "    cpu_speedup = batch_results_cpu['speedup']\n",
    "    ax.text(0.5, max(cpu_times)*0.9,\n",
    "            f'CPU: {cpu_speedup:.2f}x faster',\n",
    "            ha='center', fontsize=10, fontweight='bold', color='#f39c12')\n",
    "\n",
    "ax.set_ylabel('Inference Time (ms)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Inference Speed Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Dense PINN', 'SPINN'], fontsize=10)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n‚úÖ Saved: results/figures/performance_comparison.png\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ ALL EXPERIMENTS COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìä Final Results Summary:\")\n",
    "print(f\"   Parameters:   {dense_params:,} ‚Üí {spinn_params:,} ({reduction_pct:.1f}% reduction)\")\n",
    "print(f\"   Accuracy:     R¬≤ {dense_r2:.4f} ‚Üí {spinn_r2:.4f} ({(spinn_r2-dense_r2)/dense_r2*100:+.0f}%)\")\n",
    "if batch_results_gpu is not None:\n",
    "    print(f\"   GPU Speedup:  {gpu_speedup:.2f}x\")\n",
    "print(f\"   CPU Speedup:  {cpu_speedup:.2f}x\")\n",
    "print(\"\\nüìÅ Results saved in:\")\n",
    "print(\"   - results/checkpoints/spinn_sparse_final.pt\")\n",
    "print(\"   - results/benchmarks/metrics_comparison.json\")\n",
    "print(\"   - results/figures/performance_comparison.png\")\n",
    "print(\"\\nüìù Next: Write paper using SPARSE_IMPLEMENTATION_NOTES.md as guide!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
